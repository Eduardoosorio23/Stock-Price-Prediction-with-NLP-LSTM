{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from  nltk import FreqDist\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.collocations import *\n",
    "# nltk.download('wordnet')\n",
    "from nltk import word_tokenize, FreqDist\n",
    "\n",
    "from spacy import displacy\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Webscraped data from Reddit and twitter talking about TSLA stock\n",
    "df = pd.read_csv('static_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data=> (10193, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>date</th>\n",
       "      <th>spacy</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>$BBBY DD</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>$BBBY DD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Here comes the sun turururu $RUN $TSLA</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>Here comes the sun turururu $RUN $TSLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>$Run $Tsla f*** the suits</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>$Run $Tsla f*** the suits</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B.A.R.S - The Ultimate Meme Portfolio ğŸš€ğŸš€ğŸš€</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>B.A.R.S - The Ultimate Meme Portfolio ğŸš€ğŸš€ğŸš€</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(TSLA) vs (F)</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>(TSLA) vs (F)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       post        date  \\\n",
       "0           0                                   $BBBY DD  2021-06-02   \n",
       "1           1     Here comes the sun turururu $RUN $TSLA  2021-06-02   \n",
       "2           2                  $Run $Tsla f*** the suits  2021-06-02   \n",
       "3           3  B.A.R.S - The Ultimate Meme Portfolio ğŸš€ğŸš€ğŸš€  2021-06-01   \n",
       "4           4                              (TSLA) vs (F)  2021-06-01   \n",
       "\n",
       "                                       spacy  sentiment  subjectivity  \n",
       "0                                   $BBBY DD        0.0           0.0  \n",
       "1     Here comes the sun turururu $RUN $TSLA        0.0           0.0  \n",
       "2                  $Run $Tsla f*** the suits        0.0           0.0  \n",
       "3  B.A.R.S - The Ultimate Meme Portfolio ğŸš€ğŸš€ğŸš€        0.0           1.0  \n",
       "4                              (TSLA) vs (F)        0.0           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of the Dataset\n",
    "print(\"Shape of data=>\",df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post            0\n",
       "date            0\n",
       "spacy           0\n",
       "sentiment       0\n",
       "subjectivity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for Nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts 1:\n",
      " $SOS clean and green till Elon gets a ring. WE SHALL RISE\n",
      "Posts 2:\n",
      " Is $SPCE the next $GME.\n",
      "Posts 3:\n",
      " F IS SUPER UNDERVALUED\n",
      "Posts 4:\n",
      " $GOGO is a Starlink play\n",
      "Posts 5:\n",
      " WOW! Look what is happening with Ford (F)! It have reached 15 years high and not stoping, I think it will be one of those stocks that get tremendous momentum! Let's watch!\n"
     ]
    }
   ],
   "source": [
    "# taking a look at 5 random posts\n",
    "for index,text in enumerate(df['post'][35:40]):\n",
    "  print('Posts %d:\\n'%(index+1),text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of English Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "  def replace(match):\n",
    "    return contractions_dict[match.group(0)]\n",
    "  return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions in the reviews\n",
    "df['post']=df['post'].apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts 1:\n",
      " $SOS clean and green till Elon gets a ring. WE SHALL RISE\n",
      "Posts 2:\n",
      " Is $SPCE the next $GME.\n",
      "Posts 3:\n",
      " F IS SUPER UNDERVALUED\n",
      "Posts 4:\n",
      " $GOGO is a Starlink play\n",
      "Posts 5:\n",
      " WOW! Look what is happening with Ford (F)! It have reached 15 years high and not stoping, I think it will be one of those stocks that get tremendous momentum! Let is watch!\n"
     ]
    }
   ],
   "source": [
    "# taking a look at 5 posts after expanding contrations\n",
    "for index,text in enumerate(df['post'][35:40]):\n",
    "  print('Posts %d:\\n'%(index+1),text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the posts into lower case for the purposes of NLP\n",
    "df['post']=df['post'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing numbers and words containing numbers\n",
    "df['post']=df['post'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation\n",
    "df['post']=df['post'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing extra spaces\n",
    "df['post']=df['post'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts 1:\n",
      " bbby dd\n",
      "Posts 2:\n",
      " here comes the sun turururu run tsla\n",
      "Posts 3:\n",
      " run tsla f the suits\n",
      "Posts 4:\n",
      " bars the ultimate meme portfolio ğŸš€ğŸš€ğŸš€\n",
      "Posts 5:\n",
      " tsla vs f\n"
     ]
    }
   ],
   "source": [
    "# taking a look at 5 random posts\n",
    "for index,text in enumerate(df['post'][0:5]):\n",
    "  print('Posts %d:\\n'%(index+1),text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatizing the tokens and removing stopwords\n",
    "df['lemmatized']=df['post'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\u0010nio will be worthless in a few years</th>\n",
       "      <td>\u0010nio worthless year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a day after a day recently only been trading for months now</th>\n",
       "      <td>day day recently trade month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a pop long tsla</th>\n",
       "      <td>pop long tsla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and a dream</th>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        lemmatized\n",
       "post                                                                              \n",
       "                                                                                  \n",
       "\u0010nio will be worthless in a few years                          \u0010nio worthless year\n",
       " a day after a day recently only been trading f...    day day recently trade month\n",
       " a pop long tsla                                                     pop long tsla\n",
       " and a dream                                                                 dream"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped=df[['post','lemmatized']].groupby(by='post').agg(lambda x:' '.join(x))\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaaaaaaand</th>\n",
       "      <th>aaaaaaand</th>\n",
       "      <th>aaand</th>\n",
       "      <th>aal</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aapltsla</th>\n",
       "      <th>aaxn</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>ğ„ğ‹ğ„ğ‚ğ“ğ‘ğ„ğŠ</th>\n",
       "      <th>ğ‡ğ€ğ’</th>\n",
       "      <th>ğˆğ</th>\n",
       "      <th>ğˆğğ‚ğ‘ğ„ğ€ğ’ğ„ğƒ</th>\n",
       "      <th>ğŒğğƒğ„ğ‹</th>\n",
       "      <th>ğğ…</th>\n",
       "      <th>ğğ‘ğˆğ‚ğ„</th>\n",
       "      <th>ğ“ğ„ğ’ğ‹ğ€</th>\n",
       "      <th>ğ“ğ‡ğ„</th>\n",
       "      <th>ğ”ğ’</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\u0010nio will be worthless in a few years</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a day after a day recently only been trading for months now</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 8014 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    aa  aaa  aaaaaaaaand  \\\n",
       "post                                                                       \n",
       "                                                     0    0            0   \n",
       "\u0010nio will be worthless in a few years                0    0            0   \n",
       " a day after a day recently only been trading f...   0    0            0   \n",
       "\n",
       "                                                    aaaaaaand  aaand  aal  \\\n",
       "post                                                                        \n",
       "                                                            0      0    0   \n",
       "\u0010nio will be worthless in a few years                       0      0    0   \n",
       " a day after a day recently only been trading f...          0      0    0   \n",
       "\n",
       "                                                    aapl  aapltsla  aaxn  ab  \\\n",
       "post                                                                           \n",
       "                                                       0         0     0   0   \n",
       "\u0010nio will be worthless in a few years                  0         0     0   0   \n",
       " a day after a day recently only been trading f...     0         0     0   0   \n",
       "\n",
       "                                                    ...  ğ„ğ‹ğ„ğ‚ğ“ğ‘ğ„ğŠ  ğ‡ğ€ğ’  ğˆğ  \\\n",
       "post                                                ...                      \n",
       "                                                    ...         0    0   0   \n",
       "\u0010nio will be worthless in a few years               ...         0    0   0   \n",
       " a day after a day recently only been trading f...  ...         0    0   0   \n",
       "\n",
       "                                                    ğˆğğ‚ğ‘ğ„ğ€ğ’ğ„ğƒ  ğŒğğƒğ„ğ‹  ğğ…  \\\n",
       "post                                                                       \n",
       "                                                            0      0   0   \n",
       "\u0010nio will be worthless in a few years                       0      0   0   \n",
       " a day after a day recently only been trading f...          0      0   0   \n",
       "\n",
       "                                                    ğğ‘ğˆğ‚ğ„  ğ“ğ„ğ’ğ‹ğ€  ğ“ğ‡ğ„  ğ”ğ’  \n",
       "post                                                                       \n",
       "                                                        0      0    0   0  \n",
       "\u0010nio will be worthless in a few years                   0      0    0   0  \n",
       " a day after a day recently only been trading f...      0      0    0   0  \n",
       "\n",
       "[3 rows x 8014 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Created Document tearm matrix\n",
    "cv=CountVectorizer(analyzer='word')\n",
    "data=cv.fit_transform(df_grouped['lemmatized'])\n",
    "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n",
    "df_dtm.index=df_grouped.index\n",
    "df_dtm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>post</th>\n",
       "      <th></th>\n",
       "      <th>\u0010nio will be worthless in a few years</th>\n",
       "      <th>a day after a day recently only been trading for months now</th>\n",
       "      <th>a pop long tsla</th>\n",
       "      <th>and a dream</th>\n",
       "      <th>and do not know shit about options but i like this sub so fuck it bought puts on tsla</th>\n",
       "      <th>and i are offering the hedge fund managers who lost billions on gamestop free pillows so they have something to cry into at night</th>\n",
       "      <th>and some gratitude</th>\n",
       "      <th>annual wallstreetbets awards winners</th>\n",
       "      <th>april market crap</th>\n",
       "      <th>...</th>\n",
       "      <th>ğŸ™ the â¤ï¸ of god take your profits on tsla</th>\n",
       "      <th>ğŸš€ğŸš€ğŸš€ tsla arkk httpstco</th>\n",
       "      <th>ğŸš€ğŸš€ğŸš€ wave to tsla on your way to the moon ğŸš€ğŸš€ğŸš€</th>\n",
       "      <th>ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€tslağŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€</th>\n",
       "      <th>ğŸš¨ğŸš¨they are attacking daddy elon for revenge on his tweets if u have spare ğŸ’ buy gme and tslağŸš¨ğŸš¨</th>\n",
       "      <th>ğŸ¤‘all in tslağŸ¤‘</th>\n",
       "      <th>ğŸ¤— this made my day thanks for the shoutout and congrats on your tsla ğŸ‰ so inspiring to see retail investors be at the forefront and ahead of the curve tesla was a grassroots success story canâ€™t stop smiling elonmusk</th>\n",
       "      <th>ğŸ¦ turn tsla to more ğŸŒğŸŒğŸŒ</th>\n",
       "      <th>ğŸ¦ poll timeğŸ¦  monday march</th>\n",
       "      <th>ğŸ¦ poll timeğŸ¦ monday march</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaaand</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaand</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaand</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğğ…</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğğ‘ğˆğ‚ğ„</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğ“ğ„ğ’ğ‹ğ€</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğ“ğ‡ğ„</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ğ”ğ’</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8014 rows Ã— 9798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "post              \u0010nio will be worthless in a few years   \\\n",
       "aa           0.0                                     0.0   \n",
       "aaa          0.0                                     0.0   \n",
       "aaaaaaaaand  0.0                                     0.0   \n",
       "aaaaaaand    0.0                                     0.0   \n",
       "aaand        0.0                                     0.0   \n",
       "...          ...                                     ...   \n",
       "ğğ…           0.0                                     0.0   \n",
       "ğğ‘ğˆğ‚ğ„        0.0                                     0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€        0.0                                     0.0   \n",
       "ğ“ğ‡ğ„          0.0                                     0.0   \n",
       "ğ”ğ’           0.0                                     0.0   \n",
       "\n",
       "post          a day after a day recently only been trading for months now  \\\n",
       "aa                                                         0.0              \n",
       "aaa                                                        0.0              \n",
       "aaaaaaaaand                                                0.0              \n",
       "aaaaaaand                                                  0.0              \n",
       "aaand                                                      0.0              \n",
       "...                                                        ...              \n",
       "ğğ…                                                         0.0              \n",
       "ğğ‘ğˆğ‚ğ„                                                      0.0              \n",
       "ğ“ğ„ğ’ğ‹ğ€                                                      0.0              \n",
       "ğ“ğ‡ğ„                                                        0.0              \n",
       "ğ”ğ’                                                         0.0              \n",
       "\n",
       "post          a pop long tsla   and a dream  \\\n",
       "aa                        0.0           0.0   \n",
       "aaa                       0.0           0.0   \n",
       "aaaaaaaaand               0.0           0.0   \n",
       "aaaaaaand                 0.0           0.0   \n",
       "aaand                     0.0           0.0   \n",
       "...                       ...           ...   \n",
       "ğğ…                        0.0           0.0   \n",
       "ğğ‘ğˆğ‚ğ„                     0.0           0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                     0.0           0.0   \n",
       "ğ“ğ‡ğ„                       0.0           0.0   \n",
       "ğ”ğ’                        0.0           0.0   \n",
       "\n",
       "post          and do not know shit about options but i like this sub so fuck it bought puts on tsla  \\\n",
       "aa                                                         0.0                                        \n",
       "aaa                                                        0.0                                        \n",
       "aaaaaaaaand                                                0.0                                        \n",
       "aaaaaaand                                                  0.0                                        \n",
       "aaand                                                      0.0                                        \n",
       "...                                                        ...                                        \n",
       "ğğ…                                                         0.0                                        \n",
       "ğğ‘ğˆğ‚ğ„                                                      0.0                                        \n",
       "ğ“ğ„ğ’ğ‹ğ€                                                      0.0                                        \n",
       "ğ“ğ‡ğ„                                                        0.0                                        \n",
       "ğ”ğ’                                                         0.0                                        \n",
       "\n",
       "post          and i are offering the hedge fund managers who lost billions on gamestop free pillows so they have something to cry into at night  \\\n",
       "aa                                                         0.0                                                                                    \n",
       "aaa                                                        0.0                                                                                    \n",
       "aaaaaaaaand                                                0.0                                                                                    \n",
       "aaaaaaand                                                  0.0                                                                                    \n",
       "aaand                                                      0.0                                                                                    \n",
       "...                                                        ...                                                                                    \n",
       "ğğ…                                                         0.0                                                                                    \n",
       "ğğ‘ğˆğ‚ğ„                                                      0.0                                                                                    \n",
       "ğ“ğ„ğ’ğ‹ğ€                                                      0.0                                                                                    \n",
       "ğ“ğ‡ğ„                                                        0.0                                                                                    \n",
       "ğ”ğ’                                                         0.0                                                                                    \n",
       "\n",
       "post          and some gratitude   annual wallstreetbets awards winners  \\\n",
       "aa                           0.0                                    0.0   \n",
       "aaa                          0.0                                    0.0   \n",
       "aaaaaaaaand                  0.0                                    0.0   \n",
       "aaaaaaand                    0.0                                    0.0   \n",
       "aaand                        0.0                                    0.0   \n",
       "...                          ...                                    ...   \n",
       "ğğ…                           0.0                                    0.0   \n",
       "ğğ‘ğˆğ‚ğ„                        0.0                                    0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                        0.0                                    0.0   \n",
       "ğ“ğ‡ğ„                          0.0                                    0.0   \n",
       "ğ”ğ’                           0.0                                    0.0   \n",
       "\n",
       "post          april market crap  ...  \\\n",
       "aa                          0.0  ...   \n",
       "aaa                         0.0  ...   \n",
       "aaaaaaaaand                 0.0  ...   \n",
       "aaaaaaand                   0.0  ...   \n",
       "aaand                       0.0  ...   \n",
       "...                         ...  ...   \n",
       "ğğ…                          0.0  ...   \n",
       "ğğ‘ğˆğ‚ğ„                       0.0  ...   \n",
       "ğ“ğ„ğ’ğ‹ğ€                       0.0  ...   \n",
       "ğ“ğ‡ğ„                         0.0  ...   \n",
       "ğ”ğ’                          0.0  ...   \n",
       "\n",
       "post         ğŸ™ the â¤ï¸ of god take your profits on tsla  \\\n",
       "aa                                                 0.0   \n",
       "aaa                                                0.0   \n",
       "aaaaaaaaand                                        0.0   \n",
       "aaaaaaand                                          0.0   \n",
       "aaand                                              0.0   \n",
       "...                                                ...   \n",
       "ğğ…                                                 0.0   \n",
       "ğğ‘ğˆğ‚ğ„                                              0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                                              0.0   \n",
       "ğ“ğ‡ğ„                                                0.0   \n",
       "ğ”ğ’                                                 0.0   \n",
       "\n",
       "post         ğŸš€ğŸš€ğŸš€ tsla arkk httpstco  \\\n",
       "aa                              0.0   \n",
       "aaa                             0.0   \n",
       "aaaaaaaaand                     0.0   \n",
       "aaaaaaand                       0.0   \n",
       "aaand                           0.0   \n",
       "...                             ...   \n",
       "ğğ…                              0.0   \n",
       "ğğ‘ğˆğ‚ğ„                           0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                           0.0   \n",
       "ğ“ğ‡ğ„                             0.0   \n",
       "ğ”ğ’                              0.0   \n",
       "\n",
       "post         ğŸš€ğŸš€ğŸš€ wave to tsla on your way to the moon ğŸš€ğŸš€ğŸš€  ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€tslağŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€  \\\n",
       "aa                                                    0.0                 0.0   \n",
       "aaa                                                   0.0                 0.0   \n",
       "aaaaaaaaand                                           0.0                 0.0   \n",
       "aaaaaaand                                             0.0                 0.0   \n",
       "aaand                                                 0.0                 0.0   \n",
       "...                                                   ...                 ...   \n",
       "ğğ…                                                    0.0                 0.0   \n",
       "ğğ‘ğˆğ‚ğ„                                                 0.0                 0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                                                 0.0                 0.0   \n",
       "ğ“ğ‡ğ„                                                   0.0                 0.0   \n",
       "ğ”ğ’                                                    0.0                 0.0   \n",
       "\n",
       "post         ğŸš¨ğŸš¨they are attacking daddy elon for revenge on his tweets if u have spare ğŸ’ buy gme and tslağŸš¨ğŸš¨  \\\n",
       "aa                                                         0.0                                                \n",
       "aaa                                                        0.0                                                \n",
       "aaaaaaaaand                                                0.0                                                \n",
       "aaaaaaand                                                  0.0                                                \n",
       "aaand                                                      0.0                                                \n",
       "...                                                        ...                                                \n",
       "ğğ…                                                         0.0                                                \n",
       "ğğ‘ğˆğ‚ğ„                                                      0.0                                                \n",
       "ğ“ğ„ğ’ğ‹ğ€                                                      0.0                                                \n",
       "ğ“ğ‡ğ„                                                        0.0                                                \n",
       "ğ”ğ’                                                         0.0                                                \n",
       "\n",
       "post         ğŸ¤‘all in tslağŸ¤‘  \\\n",
       "aa                     0.0   \n",
       "aaa                    0.0   \n",
       "aaaaaaaaand            0.0   \n",
       "aaaaaaand              0.0   \n",
       "aaand                  0.0   \n",
       "...                    ...   \n",
       "ğğ…                     0.0   \n",
       "ğğ‘ğˆğ‚ğ„                  0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                  0.0   \n",
       "ğ“ğ‡ğ„                    0.0   \n",
       "ğ”ğ’                     0.0   \n",
       "\n",
       "post         ğŸ¤— this made my day thanks for the shoutout and congrats on your tsla ğŸ‰ so inspiring to see retail investors be at the forefront and ahead of the curve tesla was a grassroots success story canâ€™t stop smiling elonmusk  \\\n",
       "aa                                                         0.0                                                                                                                                                                         \n",
       "aaa                                                        0.0                                                                                                                                                                         \n",
       "aaaaaaaaand                                                0.0                                                                                                                                                                         \n",
       "aaaaaaand                                                  0.0                                                                                                                                                                         \n",
       "aaand                                                      0.0                                                                                                                                                                         \n",
       "...                                                        ...                                                                                                                                                                         \n",
       "ğğ…                                                         0.0                                                                                                                                                                         \n",
       "ğğ‘ğˆğ‚ğ„                                                      0.0                                                                                                                                                                         \n",
       "ğ“ğ„ğ’ğ‹ğ€                                                      0.0                                                                                                                                                                         \n",
       "ğ“ğ‡ğ„                                                        0.0                                                                                                                                                                         \n",
       "ğ”ğ’                                                         0.0                                                                                                                                                                         \n",
       "\n",
       "post         ğŸ¦ turn tsla to more ğŸŒğŸŒğŸŒ  ğŸ¦ poll timeğŸ¦  monday march   \\\n",
       "aa                               0.0                        0.0   \n",
       "aaa                              0.0                        0.0   \n",
       "aaaaaaaaand                      0.0                        0.0   \n",
       "aaaaaaand                        0.0                        0.0   \n",
       "aaand                            0.0                        0.0   \n",
       "...                              ...                        ...   \n",
       "ğğ…                               0.0                        0.0   \n",
       "ğğ‘ğˆğ‚ğ„                            0.0                        0.0   \n",
       "ğ“ğ„ğ’ğ‹ğ€                            0.0                        0.0   \n",
       "ğ“ğ‡ğ„                              0.0                        0.0   \n",
       "ğ”ğ’                               0.0                        0.0   \n",
       "\n",
       "post         ğŸ¦ poll timeğŸ¦ monday march   \n",
       "aa                                0.0  \n",
       "aaa                               0.0  \n",
       "aaaaaaaaand                       0.0  \n",
       "aaaaaaand                         0.0  \n",
       "aaand                             0.0  \n",
       "...                               ...  \n",
       "ğğ…                                0.0  \n",
       "ğğ‘ğˆğ‚ğ„                             0.0  \n",
       "ğ“ğ„ğ’ğ‹ğ€                             0.0  \n",
       "ğ“ğ‡ğ„                               0.0  \n",
       "ğ”ğ’                                0.0  \n",
       "\n",
       "[8014 rows x 9798 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dtm.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'aaa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'aaa'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-8dc15f1b6208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# for index,product in enumerate(df_dtm.columns):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mgenerate_wordcloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dtm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'aaa'"
     ]
    }
   ],
   "source": [
    "# Importing wordcloud for plotting word clouds and textwrap for wrapping longer text\n",
    "from wordcloud import WordCloud\n",
    "from textwrap import wrap\n",
    "\n",
    "# Function for generating word clouds\n",
    "def generate_wordcloud(data,title):\n",
    "    wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
    "    plt.show()\n",
    "   \n",
    "  \n",
    "# Transposing document term matrix\n",
    "df_dtm=df_dtm.transpose()\n",
    "\n",
    "# Plotting word cloud for each product\n",
    "# for index,product in enumerate(df_dtm.columns):\n",
    "for index,post in enumerate(df.iloc[df['sentiment'].sort_values(ascending=False)[:3].index]['post']):\n",
    "    generate_wordcloud(df_dtm[product].sort_values(ascending=False), product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>date</th>\n",
       "      <th>spacy</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bbby dd</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>$BBBY DD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bbby dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here comes the sun turururu run tsla</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>Here comes the sun turururu $RUN $TSLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>come sun turururu run tsla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run tsla f the suits</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>$Run $Tsla f*** the suits</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>run tsla f suit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bars the ultimate meme portfolio ğŸš€ğŸš€ğŸš€</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>B.A.R.S - The Ultimate Meme Portfolio ğŸš€ğŸš€ğŸš€</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bar ultimate meme portfolio ğŸš€ ğŸš€ ğŸš€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tsla vs f</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>(TSLA) vs (F)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tsla vs f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   post        date  \\\n",
       "0                               bbby dd  2021-06-02   \n",
       "1  here comes the sun turururu run tsla  2021-06-02   \n",
       "2                  run tsla f the suits  2021-06-02   \n",
       "3  bars the ultimate meme portfolio ğŸš€ğŸš€ğŸš€  2021-06-01   \n",
       "4                             tsla vs f  2021-06-01   \n",
       "\n",
       "                                       spacy  sentiment  subjectivity  \\\n",
       "0                                   $BBBY DD        0.0           0.0   \n",
       "1     Here comes the sun turururu $RUN $TSLA        0.0           0.0   \n",
       "2                  $Run $Tsla f*** the suits        0.0           0.0   \n",
       "3  B.A.R.S - The Ultimate Meme Portfolio ğŸš€ğŸš€ğŸš€        0.0           1.0   \n",
       "4                              (TSLA) vs (F)        0.0           0.0   \n",
       "\n",
       "                          lemmatized  \n",
       "0                            bbby dd  \n",
       "1         come sun turururu run tsla  \n",
       "2                    run tsla f suit  \n",
       "3  bar ultimate meme portfolio ğŸš€ ğŸš€ ğŸš€  \n",
       "4                          tsla vs f  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Post with Highest Sentiment:\n",
      "Post 1:\n",
      " what ev stock is the best bet nio or arvl\n",
      "Post 2:\n",
      " âš ï¸breakingâš ï¸ tesla china ğŸ‡¨ğŸ‡³ sold china made model y in feb an impressive growth vs jan tsla httpstco\n",
      "Post 3:\n",
      " tsla earnings report best quarter ever\n"
     ]
    }
   ],
   "source": [
    "#Showing posts with the higest sentiment\n",
    "print(\"3 Post with Highest Sentiment:\")\n",
    "for index,post in enumerate(df.iloc[df['sentiment'].sort_values(ascending=False)[:3].index]['post']):\n",
    "  print('Post {}:\\n'.format(index+1),post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Post with Lowest Sentiment:\n",
      "Post 1:\n",
      " i have buying power on robinhood what terrible position can i take on tsla before earnings\n",
      "Post 2:\n",
      " to all the miserable bastards that missed the tsla rocket here is what your gainz could have looked like\n",
      "Post 3:\n",
      " ohh stock market you are a cruel mistress\n"
     ]
    }
   ],
   "source": [
    "#Post with the lowest sentiment\n",
    "print(\"3 Post with Lowest Sentiment:\")\n",
    "for index,post in enumerate(df.iloc[df['sentiment'].sort_values(ascending=True)[:3].index]['post']):\n",
    "  print('Post {}:\\n'.format(index+1),post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
